Gathering data was relatively straightforward. Although I do not understand twitter (I still do not), I figured that data is data and twitter API is just another API. Tweepy's documentation is quite well done. It facilitated access to twitter's API methods. In fact tweepy did everything. I did not have to understand twitter at all. Although APIs fascinate me, Twitter does not. A platform that is used by racist nationalists in USA is a platform in which no one should take interest.

The one thing that interested me with twitter is the authentication part. I discovered that twitter allows both OAuth 1.0a and OAuth 2.0. Fortunately, tweepy has 2 different handlers for both, namely tweepy.OAuthHandler and tweepy.AppAuthHandler, respectively.

I experimented with both authentication handlers just accessing only one twit ID with following code:
```
twitid_lst = twitarch_df.tweet_id.values
one_tweet = tweet_id_lst[0]
tweet = api.get_status(one_tweet, tweet_mode='extended')
print(tweet)
```

For the purpose of this project, I opted to use AppAuthHandler since it required NO access tokens -- just the bearer token that was generated at the same time as the twitter API keys.
I also used `extended` mode as opposed to `compat` mode since I did not really know what other information I needed from twitter for this purpose. I wanted to gain access to twitter data and APIs exactly ONE time and never again. And yes, other than the quick experimentation with the authentication handlers, I only had to use this twitter developer account exactly once, and hopefully never again.

These are my analogues in order to dummify the already moronic twitter platform.
tweet: a text message
retweet: a text message that has been shared.
retweet count: the number of times a specific tweet has been shared
favorite count: I have absolutely no idea.

Visual assessment
twitter-archive-enhanced-2 file
When the dog types are pluralized in text, for example, "puppers", they are categorized as None.
Several fields in twitter-archive have no data at all.
expanded_url seems to be an important column. However some rows do not have them.
Some of the ratings (based on rating_numerator and rating_denominator fields) are beyond the 10 out of 10. It may be intentional.
The text have mixed items. But probably intentional


timestamp validity (cannot take advantage of time series functionality)
expanded_url completeness


there might be some consistency issues with capitalization in the image predictions table. But I think it's quite trivial.

Tidiness (structural)
According to project details, those terms are different dog stages hence they are value terms and should not be field names.
The fields doggo floofer pupper and puppo should be mutually exclusive since the dogtionary implied ordinal categories with the use of "stages". However, visually there are some animals that are combination of stages. In fact the dogtionary defines each stage as forms of other stages. So there is no clear cut definition of the stages. 4 variables
the field `retweeted_status_id` seems redundant as every row that has data in that field also has text the begins with "RT"


Structural
IDs as floats do not make sense at all. IDs as integers might make sense. I do not know how twitter uses its tweet_id but for my purpose I will create a new column with tweet_id as strings.

